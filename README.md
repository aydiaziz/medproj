# ğŸ¤– DÃ©tecteur de Signes â€” Sign Recognition System

> **Real-time hand gesture detection and recognition using MediaPipe Hands, FastAPI, and WebSocket**

Un systÃ¨me complet de dÃ©tection de signes en temps rÃ©el avec interface web moderne et architecture serveur centralisÃ©e.

---

## ğŸ“‹ Table des matiÃ¨res

1. [Vue d'ensemble](#vue-densemble)
2. [Architecture](#architecture)
3. [Installation](#installation)
4. [Usage](#usage)
5. [API Reference](#api-reference)
6. [Structure du projet](#structure-du-projet)
7. [Technologies](#technologies)
8. [Troubleshooting](#troubleshooting)

---

## ğŸ¯ Vue d'ensemble

Ce projet implÃ©mente une **architecture centralisÃ©e pour la dÃ©tection de mains en temps rÃ©el** :

### CaractÃ©ristiques principales :

- âœ… **CamÃ©ra unique et persistante** : une seule ouverture au dÃ©marrage, fermeture Ã  l'arrÃªt
- âœ… **Thread dÃ©diÃ©** : lecture continue des frames en background
- âœ… **MediaPipe Hands** : dÃ©tection des 21 landmarks de chaque main
- âœ… **WebSocket live** : streaming des dÃ©tections au navigateur (~10 Hz)
- âœ… **Interface web** : affichage des landmarks en grille responsive
- âœ… **Thread-safe** : utilisation de locks pour accÃ¨s concurrent

### Data Flow :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Architecture                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  [STARTUP]                                                  â”‚
â”‚      â†“                                                       â”‚
â”‚  â€¢ Ouvrir camÃ©ra (une fois)                                â”‚
â”‚  â€¢ Initialiser MediaPipe HandLandmarker                    â”‚
â”‚  â€¢ DÃ©marrer camera_reader_thread                           â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚     CAMERA READER THREAD (continu)              â”‚       â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚       â”‚
â”‚  â”‚  â”‚ cv2.read()   â”‚â”€â”€â†’   â”‚ MediaPipe    â”‚â”€â”€â†’     â”‚       â”‚
â”‚  â”‚  â”‚ (30 FPS)     â”‚      â”‚ detect()     â”‚  last_ â”‚       â”‚
â”‚  â”‚  â”‚ frame = F    â”‚      â”‚ detection    â”‚  frame â”‚       â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚            â†“                          â†“                     â”‚
â”‚       [Lock]                    [Lock]                      â”‚
â”‚            â†“                          â†“                     â”‚
â”‚  last_frame â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ last_detection    â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚         WEBSOCKET HANDLER (per-client)          â”‚       â”‚
â”‚  â”‚  â€¢ Lire last_frame (pas de gestion)             â”‚       â”‚
â”‚  â”‚  â€¢ Lire last_detection                          â”‚       â”‚
â”‚  â”‚  â€¢ Envoyer au client via JSON (~10 Hz)         â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚            â†“                                                â”‚
â”‚       [Network]                                            â”‚
â”‚            â†“                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚         FRONTEND (Browser)                      â”‚       â”‚
â”‚  â”‚  â€¢ Afficher count de mains                      â”‚       â”‚
â”‚  â”‚  â€¢ Grille de 21 landmarks par main             â”‚       â”‚
â”‚  â”‚  â€¢ Coords (x, y, z) + confiance               â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                              â”‚
â”‚  [SHUTDOWN]                                                 â”‚
â”‚      â†“                                                       â”‚
â”‚  â€¢ ArrÃªter camera_reader_thread                           â”‚
â”‚  â€¢ Fermer camÃ©ra (une fois)                               â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ—ï¸ Architecture

### Backend (`backend/app_new.py`)

#### 1. **CameraManager** â€” Gestion centralisÃ©e de la camÃ©ra

```python
camera_manager = CameraManager(device=0, width=640, height=480)

# Ã€ startup
camera_manager.init()  # Ouvre camÃ©ra UNE FOIS, dÃ©marre thread

# Dans le thread dÃ©diÃ©
def _reader_loop():
    while running:
        ret, frame = cap.read()  # Lecture continue
        if ret:
            last_frame = frame.copy()
            detection = hand_detector.detect(frame, frame_count)
            last_detection = detection

# Ã€ shutdown
camera_manager.shutdown()  # Ferme camÃ©ra, arrÃªte thread
```

**Avantages** :
- Ã‰vite les rÃ©ouvertures camÃ©ra (qui causent des `ret=False`)
- Une seule instance partagÃ©e
- Thread-safe avec `threading.RLock()`
- WebSocket lit uniquement, ne gÃ¨re jamais la camÃ©ra

#### 2. **HandLandmarkerWrapper** â€” DÃ©tection MediaPipe

```python
class HandLandmarkerWrapper:
    def detect(frame: np.ndarray, frame_count: int) -> dict:
        """DÃ©tecte les mains dans la frame."""
        result = self.landmarker.detect_for_video(mp_image, frame_count)
        # Retourne:
        {
            "num_hands": 2,
            "hands": [
                {
                    "index": 0,
                    "label": "Left",
                    "confidence": 0.95,
                    "landmarks": [
                        {"x": 0.45, "y": 0.38, "z": -0.08, "presence": 1.0},
                        ...21 landmarks...
                    ]
                },
                ...
            ]
        }
```

**Points clÃ©s** :
- Utilise MediaPipe Tasks API (VIDEO mode)
- DÃ©tecte jusqu'Ã  2 mains simultanÃ©ment
- Landmarks : 21 points par main (x, y, z, prÃ©sence)
- Fallback automatique IMAGE mode si VIDEO Ã©choue

#### 3. **WebSocket Handler** â€” Streaming live

```python
@app.websocket("/ws")
async def websocket_camera(ws: WebSocket):
    # Accepte la connexion
    await ws.accept()
    
    # Boucle principale : lire et envoyer
    while True:
        # Lire derniÃ¨re frame (non-blocking)
        frame_data = camera_manager.read_frame()
        
        # Construire message
        message = {
            "type": "detection",
            "frames_total": 150,
            "timestamp": "2025-12-25T14:30:45...",
            "detection": {...}
        }
        
        # Envoyer au client
        await ws.send_json(message)  # ~10 Hz
```

### Frontend (`frontend/index.html`)

#### 1. **WebSocket Client** â€” Connexion au serveur

```javascript
const ws = new WebSocket('ws://localhost:8000/ws');

ws.onmessage = (evt) => {
    const data = JSON.parse(evt.data);
    updateDetection(data);  // Afficher landmarks
};
```

#### 2. **Detection Display** â€” Rendu des mains

```javascript
function renderHandLandmarks(hand) {
    // Pour chaque main:
    // - Label (Left/Right) + Confiance
    // - Grille de 21 landmarks
    // - Coords (x, y, z) arrondies
}
```

---

## ğŸ“¦ Installation

### 1. PrÃ©requis

- **Python 3.11** (recommandÃ©)
- **CamÃ©ra USB** (webcam)
- **Navigateur moderne** (Chrome, Firefox, Edge)

### 2. Setup venv

```bash
# CrÃ©er venv
python -m venv .venv311

# Activer
.venv311\Scripts\activate  # Windows
source .venv311/bin/activate  # Linux/Mac

# Installer dÃ©pendances
pip install -r requirements.txt
```

### 3. ModÃ¨le MediaPipe

Le fichier `backend/models/hand_landmarker.task` est nÃ©cessaire. S'il manque :

```bash
mkdir -p backend/models
cd backend/models
# Le serveur tentera de tÃ©lÃ©charger depuis Google si absent
```

---

## ğŸš€ Usage

### DÃ©marrer le serveur

```bash
cd medproj
.venv311\Scripts\python.exe -m uvicorn backend.app_new:app --host 127.0.0.1 --port 8000
```

**Output** :
```
INFO:     Started server process [1234]
INFO:     Application startup complete
INFO:     Uvicorn running on http://127.0.0.1:8000
```

### AccÃ©der au frontend

Ouvrir navigateur :
```
http://127.0.0.1:8000
```

### Utiliser l'interface

1. **"DÃ©marrer dÃ©tection"** : lance la dÃ©tection
2. **Placer mains devant camÃ©ra** : landmarks s'affichent
3. **"ArrÃªter dÃ©tection"** : pause l'affichage

### Logs du serveur

```
INFO:     127.0.0.1:60267 - "WebSocket /ws" [accepted]
INFO:     connection open
WARNING:root:Erreur dÃ©tection mains: ... (si capteur occultÃ©)
```

---

## ğŸ“¡ API Reference

### HTTP Endpoints

#### `GET /`
Retourne la page HTML du frontend.

```
curl http://127.0.0.1:8000/
â†’ <html>...</html>
```

#### `GET /health`
Status de l'application.

```
curl http://127.0.0.1:8000/health
â†’ {
    "status": "ok",
    "camera_ready": true,
    "frames_read": 150
  }
```

### WebSocket Endpoint

#### `WS /ws`
Streaming des dÃ©tections MediaPipe.

**Message Client â†’ Serveur** : (none â€” just websocket, no JSON client â†’ server)

**Message Serveur â†’ Client** :
```json
{
  "type": "detection",
  "frames_total": 150,
  "timestamp": "2025-12-25T14:30:45.123456+00:00",
  "detection": {
    "num_hands": 2,
    "hands": [
      {
        "index": 0,
        "label": "Left",
        "confidence": 0.952,
        "landmarks": [
          {
            "x": 0.4513,
            "y": 0.3847,
            "z": -0.0827,
            "presence": 1.0
          },
          ...21 landmarks total...
        ]
      },
      {
        "index": 1,
        "label": "Right",
        "confidence": 0.948,
        "landmarks": [...]
      }
    ]
  }
}
```

**FrÃ©quence** : ~10 Hz (1 message toutes les 100 ms)

**Landmarks** : 21 points par main (MediaPipe standard)
- 0: Wrist
- 1-4: Thumb
- 5-8: Index
- 9-12: Middle
- 13-16: Ring
- 17-20: Pinky

---

## ğŸ“ Structure du projet

```
medproj/
â”œâ”€â”€ README.md                          # Ce fichier
â”œâ”€â”€ requirements.txt                   # DÃ©pendances Python
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app_new.py                     # Serveur FastAPI (ACTIF)
â”‚   â”œâ”€â”€ app.py                         # Ancien serveur (dÃ©prÃ©ciÃ©)
â”‚   â”œâ”€â”€ tts.py                         # Module TTS (optionnel)
â”‚   â”œâ”€â”€ signs_db.py                    # SQLite signs database
â”‚   â””â”€â”€ models/
â”‚       â””â”€â”€ hand_landmarker.task       # ModÃ¨le MediaPipe (tÃ©lÃ©chargÃ© auto)
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ index.html                     # Interface web (servie par /route)
â””â”€â”€ .venv311/                          # Virtual environment Python 3.11
```

### Fichiers clÃ©s

| Fichier | RÃ´le |
|---------|------|
| `backend/app_new.py` | â­ Serveur principal (CameraManager + HandLandmarker + WebSocket) |
| `backend/app.py` | Ancien serveur (per-connection camera, deprecated) |
| `frontend/index.html` | Interface web (affichage landmarks, contrÃ´les) |
| `requirements.txt` | DÃ©pendances (`fastapi`, `uvicorn`, `opencv-python`, `mediapipe`, etc.) |

---

## ğŸ› ï¸ Technologies

### Backend
- **FastAPI** : Framework web asynchrone
- **Uvicorn** : Serveur ASGI
- **OpenCV (cv2)** : Capture camÃ©ra
- **MediaPipe** : DÃ©tection mains (Tasks API)
- **Python 3.11** : Runtime

### Frontend
- **HTML5** : Markup
- **CSS3** : Styling moderne
- **JavaScript (vanilla)** : WebSocket client
- **getUserMedia API** : AperÃ§u camÃ©ra local (optionnel)

### Infrastructure
- **WebSocket** : Communication bidirectionnelle temps-rÃ©el
- **JSON** : Format Ã©change donnÃ©es
- **Threading** : Concurrence Python
- **asyncio** : Programmation asynchrone FastAPI

---

## ğŸ› Troubleshooting

### âŒ "Impossible d'ouvrir la camÃ©ra"

**Cause** : CamÃ©ra non connectÃ©e ou permissions refusÃ©es

**Solution** :
```python
# VÃ©rifier camÃ©ra disponible
python -c "import cv2; cap = cv2.VideoCapture(0); print('OK' if cap.isOpened() else 'FAIL')"

# Essayer device 1, 2, etc.
# Dans app_new.py: CAMERA_DEVICE = 1
```

### âŒ "MediaPipe Tasks API non disponible"

**Cause** : Import Ã©choue (version mediapipe incompatible)

**Solution** :
```bash
# RÃ©installer mediapipe
pip uninstall mediapipe -y
pip install mediapipe==0.10.31
```

### âŒ "Erreur envoi WebSocket: ..."

**Cause** : Client dÃ©connectÃ© (normal Ã  l'arrÃªt)

**Solution** : Rien â€” c'est attendu. VÃ©rifier dans logs :
```
INFO:     127.0.0.1:60267 - "WebSocket /ws" [accepted]
INFO:     connection closed  # â† Normal
```

### âŒ Port 8000 dÃ©jÃ  utilisÃ©

**Cause** : Autre serveur en Ã©coute

**Solution** :
```bash
# Tuer ancien processus
taskkill /F /IM python.exe  # Windows
lsof -i :8000 | grep -v PID | awk '{print $2}' | xargs kill -9  # Linux/Mac

# Ou utiliser autre port
uvicorn backend.app_new:app --host 127.0.0.1 --port 8001
```

### âŒ Landmarks vides ou "0 mains dÃ©tectÃ©es"

**Cause** : DÃ©tecteur pas actif ou mains hors-champ

**Solution** :
1. Cliquer "â–¶ DÃ©marrer dÃ©tection"
2. Placer mains devant camÃ©ra (bien visibles)
3. VÃ©rifier stats "Frames traitÃ©es" augmente
4. VÃ©rifier WebSocket connectÃ© ("ConnectÃ© âœ“")

---

## ğŸ“ Concepts clÃ©s

### Pourquoi une camÃ©ra centralisÃ©e ?

**ProblÃ¨me (ancien app.py)** :
- Ouvrir camÃ©ra par WebSocket connection
- Si 2 clients â†’ 2 appels `cv2.VideoCapture(0)`
- RÃ©sultat : `ret=False`, reopen loops, instabilitÃ©

**Solution (app_new.py)** :
- 1 camÃ©ra = 1 ouverture = 1 thread
- Thread lit en continu, stocke `last_frame`
- Tous les clients lisent `last_frame` (pas de rÃ©ouverture)
- Robuste, scalable, thread-safe

### Pourquoi VIDEO mode MediaPipe ?

**IMAGE mode** :
- 1 frame = 1 dÃ©tection indÃ©pendante
- Pas de contexte temporel

**VIDEO mode** :
- Utilise frames prÃ©cÃ©dentes (contexte)
- Plus rapide, plus stable
- Meilleure dÃ©tection sur mouvements

---

## ğŸ“ˆ Performance

### Metrics

| MÃ©trique | Valeur |
|----------|--------|
| RÃ©solution camÃ©ra | 640Ã—480 (configurable) |
| FPS camÃ©ra | 30 (configurable) |
| FPS dÃ©tection | ~15-20 (throttle) |
| FrÃ©quence WebSocket | ~10 Hz (configurable) |
| Landmarks par main | 21 points |
| Mains simultanÃ©es | Jusqu'Ã  2 |
| Latence dÃ©tection | ~30-50 ms |
| Bande passante WebSocket | ~5-10 KB/s |

### Optimisations

1. **Frame skipping** : traiter 1/2 frames (throttle CPU)
2. **Throttle WebSocket** : ~10 Hz (pas utile d'aller plus vite)
3. **Copy-on-read** : `frame.copy()` pour Ã©viter race conditions
4. **Lock-free stats** : logging sans contention

---

## ğŸ”® Futures amÃ©liorations

- [ ] Reconnaissance gestes (LSTM/transformer)
- [ ] TTS French synth
- [ ] Base de donnÃ©es gestes
- [ ] Multi-client robustness (load balancing)
- [ ] WebRTC pour bandwidth reduit
- [ ] GPU acceleration (CUDA/OpenGL)
- [ ] Configuration UI (rÃ©solution, FPS, confiance)

---

## ğŸ“ License

MIT (ou selon votre prÃ©fÃ©rence)

## ğŸ‘¥ Auteur

Created with â¤ï¸ for sign recognition research

---

**Last updated**: 2025-12-26
